{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed4186fc-18af-4066-9762-048374bf0448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import string\n",
    "from typing import List\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.training import Example\n",
    "from spacy.pipeline.spancat import DEFAULT_SPANCAT_MODEL\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "#instantiate blank spaCy object\n",
    "nlp = spacy.blank('en')\n",
    "#define your span key name\n",
    "span_key = \"sc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07407bf5-1a25-49ce-ab39-f86ce72cf30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data and fill nans with sentence #s\n",
    "ner_data = (pd.read_csv(\"data.csv\", encoding='ISO-8859-1')\n",
    "            .fillna(method='ffill'))\n",
    "\n",
    "#replace tags we don't care about with 'O'\n",
    "ents_to_replace = ['tim', 'gpe', 'art', 'eve', 'nat']\n",
    "bad_ents = []\n",
    "for ent in list(set(ner_data.Tag)):\n",
    "    if any(ent.endswith(e) for e in ents_to_replace):\n",
    "        bad_ents.append(ent)\n",
    "        \n",
    "ner_data = ner_data.replace(bad_ents, 'O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c91fdf9a-7709-4f5a-9965-d76fdd9ca318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_span_indx(\n",
    "    labels: List[str],\n",
    "    words: List[str],\n",
    "    sentence: str\n",
    ") -> List[tuple]:\n",
    "    \"\"\"Gets span starts and ends for Spacy spancat component.\n",
    "        \n",
    "        Returns list of tuples where the first element of the \n",
    "        tuple is the span start, the second element of the tuple\n",
    "        is the span end and the third element of the tuple is\n",
    "        the span category. \n",
    "    \"\"\"\n",
    "    #gets list of indices corresponding to labelled words \n",
    "    label_indx = []\n",
    "    temp_list = []\n",
    "\n",
    "    for i, l in enumerate(labels):\n",
    "        if l != 'O':\n",
    "            temp_list.append(i)\n",
    "        else:\n",
    "            label_indx.append(temp_list)\n",
    "            temp_list = []    \n",
    "        if i == len(labels) - 1:\n",
    "            label_indx.append(temp_list)\n",
    "\n",
    "    clean_label_indx = [x for x in label_indx if len(x) > 0]\n",
    "\n",
    "    spans = []\n",
    "    for indx in clean_label_indx:\n",
    "        if len(indx) == 1:\n",
    "            span = words[indx[0]]\n",
    "            label = labels[indx[0]].split('-')[-1].upper()\n",
    "        else:\n",
    "            span = ' '.join([words[i] for i in indx])  \n",
    "            label = [labels[i].split('-')[-1].upper() for i in indx][0]\n",
    "        #remove punctuation and strip whitespace for spans\n",
    "        span_clean = span.translate(str.maketrans('', '', string.punctuation))\n",
    "        for m in re.finditer(span_clean, sentence):\n",
    "            spans.append((m.start(), m.end(), label))\n",
    "    \n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7daa306-e361-49ec-abec-9ac4467e019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create spaCy compliant training data \n",
    "train_data = []\n",
    "for sent, sent_info in ner_data.groupby(\"Sentence #\"):\n",
    "    words = list(sent_info[\"Word\"])\n",
    "    #convert words to sentence and get rid of spaces between punctuation characters\n",
    "    sentence = re.sub(r'\\s([?.!\"](?:\\s|$))', r'\\1', \" \".join(words))\n",
    "    #get labels\n",
    "    labels = list(sent_info['Tag'])\n",
    "    #identify token span start, span ends and span category\n",
    "    span_ents = get_span_indx(labels, words, sentence)\n",
    "    #create spaCy compliant spans[span_key] dict\n",
    "    annotation = {'spans':{span_key: span_ents}}    \n",
    "    #convert sentence and annotation into spaCy examples\n",
    "    train_data.append(Example.from_dict(nlp.make_doc(sentence), annotation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf46f1ec-9429-4150-9f39-088f2e518284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spancat config - the definitions of each parameter are taken from spaCy's documentation \n",
    "config = {\n",
    "    #this refers to the minimum probability to consider a prediction positive\n",
    "    \"threshold\": 0.5,\n",
    "    #the span key refers to the key in doc.spans \n",
    "    \"spans_key\": span_key,\n",
    "    #this refers to the maximum number of labels to consider positive per span\n",
    "    \"max_positive\": None,\n",
    "     #a model instance that is given a list of documents with start end indices representing the labelled spans\n",
    "    \"model\": DEFAULT_SPANCAT_MODEL,\n",
    "    #A function that suggests spans. This suggester is fixed n-gram length of up to 3 tokens\n",
    "    \"suggester\": {\"@misc\": \"spacy.ngram_suggester.v1\", \"sizes\": [1, 2, 3]},\n",
    "}\n",
    "#add spancat component to nlp object\n",
    "nlp.add_pipe(\"spancat\", config=config)\n",
    "#get spancat component \n",
    "span=nlp.get_pipe('spancat')\n",
    "\n",
    "#Add labels to spancat component \n",
    "for label in ('GEO', 'PER', 'ORG'):\n",
    "    span.add_label(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5c189af-bc08-4d50-b371-f457c82fbde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get pipe you want to train on \n",
    "pipe_exceptions = [\"spancat\"]\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "\n",
    "# initialise spacy object \n",
    "nlp.initialize()\n",
    "sgd = nlp.create_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c95c3eb-4654-4d5b-9291-058d5af497fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
